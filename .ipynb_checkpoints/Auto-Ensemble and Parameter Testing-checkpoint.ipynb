{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Determine if Hyper-Parameters are Distinct or Common Across Pitchers "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Import necessary packages\n",
    "import psycopg2\n",
    "import sys  \n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from config import REDSHIFT_CONFIG\n",
    "from src.features import *\n",
    "from src.utils import *\n",
    "from src.validation import *\n",
    "\n",
    "reload(sys)\n",
    "sys.setdefaultencoding('utf8')\n",
    "\n",
    "from src.exploration import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Establish a connection to the redshift database\n",
    "conn = create_rs_conn(config=REDSHIFT_CONFIG)\n",
    "cur = conn.cursor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Increase the number of columns displayed with Pandas\n",
    "pd.set_option('display.max_columns', 500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>max</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2015-07-21</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          max\n",
       "0  2015-07-21"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cur.execute('''select max(date) from all_pitch_data_reclass limit 10;''')\n",
    "rows = cur.fetchall()\n",
    "header = [colnames[0] for colnames in cur.description]\n",
    "test = pd.DataFrame(rows)\n",
    "test.columns = header\n",
    "test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Modify the function to randomly sample pitchers from the db"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from random import sample, seed\n",
    "def randomly_sample_pitchers2(cursor, num_pitchers = 5, min_pitch_count = 600, min_date = '2015-01-01', seed_num = None):\n",
    "    '''Takes a random sample of pitchers from the db represented by \"cursor\" and returns a Pandas DF with\n",
    "    the specified number ofpitchers who have thrown at least \"min_pitch_count\" pitches\n",
    "    Input:\n",
    "        cursor: DB handle\n",
    "        num_pitchers: The number of pitchers whose data you want returned\n",
    "        min_pitch_count: Minimum number of pitches a pitcher must have thrown in order to be considered in the \n",
    "            random sampling\n",
    "        seed_num: If you want to be able to replicated the results, set a seed\n",
    "    Output: Pandas DF containing pitch data for the randomly sampled pitchers'''\n",
    "    \n",
    "    cur = cursor\n",
    "    \n",
    "    #Get all pitchers meeting the min pitches criterion\n",
    "    get_pitchers_query = '''SELECT pitcher, \n",
    "                                COUNT(*) as tot_pitch_count, \n",
    "                                MAX(date) as maximum_date\n",
    "                        FROM all_pitch_data_reclass\n",
    "                        GROUP BY pitcher\n",
    "                        HAVING count(*) >= %d AND \n",
    "                                MAX(date) > '%s'\n",
    "                        ORDER BY pitcher''' % (min_pitch_count, min_date)\n",
    "    cur.execute(get_pitchers_query)\n",
    "    \n",
    "    #Get all the pitcher ids and sample from them\n",
    "    if seed_num is not None:\n",
    "        seed(seed_num)\n",
    "    \n",
    "    rows = cur.fetchall()\n",
    "    header = [colnames[0] for colnames in cur.description]\n",
    "    pitcher_df = pd.DataFrame(rows)\n",
    "    pitcher_df.columns = header\n",
    "    \n",
    "    pitcher_id_sample = sample(pitcher_df['pitcher'].values, num_pitchers)\n",
    "    \n",
    "    pitcher_df = pitcher_df[pitcher_df['pitcher'].isin(pitcher_id_sample)]\n",
    "    \n",
    "    return pitcher_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#test it out\n",
    "pitcher_list = randomly_sample_pitchers2(cur, min_pitch_count = 1000, seed_num = 35, num_pitchers=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pitcher</th>\n",
       "      <th>tot_pitch_count</th>\n",
       "      <th>maximum_date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>121</th>\n",
       "      <td>450729</td>\n",
       "      <td>17088</td>\n",
       "      <td>2015-07-18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>126</th>\n",
       "      <td>451661</td>\n",
       "      <td>2112</td>\n",
       "      <td>2015-07-21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>242</th>\n",
       "      <td>493159</td>\n",
       "      <td>1660</td>\n",
       "      <td>2015-06-22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>250</th>\n",
       "      <td>501822</td>\n",
       "      <td>1936</td>\n",
       "      <td>2015-06-14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>330</th>\n",
       "      <td>523989</td>\n",
       "      <td>4795</td>\n",
       "      <td>2015-07-20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>331</th>\n",
       "      <td>527048</td>\n",
       "      <td>3383</td>\n",
       "      <td>2015-07-17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>333</th>\n",
       "      <td>533167</td>\n",
       "      <td>3741</td>\n",
       "      <td>2015-07-21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>382</th>\n",
       "      <td>547888</td>\n",
       "      <td>3127</td>\n",
       "      <td>2015-07-17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>410</th>\n",
       "      <td>573204</td>\n",
       "      <td>1561</td>\n",
       "      <td>2015-04-30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>426</th>\n",
       "      <td>595307</td>\n",
       "      <td>2647</td>\n",
       "      <td>2015-07-21</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     pitcher  tot_pitch_count maximum_date\n",
       "121   450729            17088   2015-07-18\n",
       "126   451661             2112   2015-07-21\n",
       "242   493159             1660   2015-06-22\n",
       "250   501822             1936   2015-06-14\n",
       "330   523989             4795   2015-07-20\n",
       "331   527048             3383   2015-07-17\n",
       "333   533167             3741   2015-07-21\n",
       "382   547888             3127   2015-07-17\n",
       "410   573204             1561   2015-04-30\n",
       "426   595307             2647   2015-07-21"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pitcher_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Function to calculate the naive accuracy for a pitcher\n",
    "def naive_accuracy(data_dict):\n",
    "    biggest_count = data_dict['test_targets'].value_counts()[0]\n",
    "    all_counts = data_dict['test_targets'].value_counts().sum()\n",
    "    return round(float(biggest_count) / all_counts, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def subset_data(modeling_dict, cols_of_interest):\n",
    "    new_dict = modeling_dict.copy()\n",
    "    new_dict['train_data'] = new_dict['train_data'][cols_of_interest]\n",
    "    new_dict['test_data'] = new_dict['test_data'][cols_of_interest]\n",
    "    return new_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.grid_search import RandomizedSearchCV\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from scipy.stats import randint as sp_randint\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def run_randomsearch_classifier2(classifier, data_dict):\n",
    "    \"\"\"Given a classifier and a data dictionary containing 'train_data' and 'test_data' (as pandas DFs),\n",
    "    This runs the classifier and outputs the accuracy of the classifier on the test data.\"\"\"\n",
    "    \n",
    "    classifier_dict = {}\n",
    "    \n",
    "    # Fit a model on all the data and features\n",
    "    classifier.fit(data_dict['train_data'], data_dict['train_targets'])\n",
    "    \n",
    "    #print the best parameters\n",
    "    classifier_dict['params'] = classifier.best_params_\n",
    "    \n",
    "    classifier_dict['baseline_accuracy'] = naive_accuracy(data_dict)\n",
    "    classifier_dict['accuracy'] = accuracy_score(data_dict['test_targets'], \n",
    "                                                 classifier.predict(data_dict['test_data']))\n",
    "    \n",
    "    # Return the dev performance score.\n",
    "    return classifier_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "cols_of_interest = ([u'b', u's', u'on_1b', u'on_2b', u'on_3b', u'o', \n",
    "              u'home_wins',u'home_loss', u'away_wins', u'away_loss', \n",
    "              u'stand_L'] + [u'Not_Fastball_pb_prior',\n",
    "                                u'Not_Fastball_pbs_prior', u'Fastball_pb_prior', u'Fastball_pbs_prior'] +\n",
    "                     [u'Not_Fastball_pc_prior', u'Not_Fastball_pcs_prior',\n",
    "                               u'Fastball_pc_prior', u'Fastball_pcs_prior'] + \n",
    "                    [u'Not_Fastball_pg_prior', u'Not_Fastball_pgs_prior', \n",
    "                               u'Fastball_pg_prior', u'Fastball_pgs_prior'] +\n",
    "                    [u'last_pitch_type_Fastball', u'last_pitch_type_Not_Fastball',\n",
    "       u'last_pitch_type_not_available', u'second_last_pitch_type_Fastball',\n",
    "       u'second_last_pitch_type_Not_Fastball',\n",
    "       u'second_last_pitch_type_not_available',\n",
    "       u'third_last_pitch_type_Fastball',\n",
    "       u'third_last_pitch_type_Not_Fastball',\n",
    "       u'third_last_pitch_type_not_available', u'prev_pitches_mean_start_speed', u'prev_pitches_mean_end_speed',\n",
    "       u'prev_pitches_mean_break_y', u'prev_pitches_mean_break_angle',\n",
    "       u'prev_pitches_mean_break_length'] + [u'ingame_pitch_count', u'cur_season', u'season_pitch_count'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Get the parameters for the four models to search over\n",
    "log_params = {'penalty': ['l1', 'l2'],\n",
    "              'C' : [0.1, 0.5, 1.0, 2.0, 5.0, 7.0],\n",
    "              'random_state' : [35]}\n",
    "gbm_params = {'loss' : ['deviance'],\n",
    "              'n_estimators' : [10, 50, 100, 150, 250, 350, 500],\n",
    "              \"max_depth\": [3, None],\n",
    "              \"max_features\": [None, 'auto'],\n",
    "              \"min_samples_split\": sp_randint(1, 11),\n",
    "              \"min_samples_leaf\": sp_randint(1, 11),\n",
    "             'random_state': [35]}\n",
    "rf_params = {'n_estimators': [10, 50, 100, 150, 250, 350, 500],\n",
    "                \"max_depth\": [3, None],\n",
    "              \"max_features\": [None, 'auto'],\n",
    "              \"min_samples_split\": sp_randint(1, 11),\n",
    "              \"min_samples_leaf\": sp_randint(1, 11),\n",
    "             'random_state': [35]}\n",
    "lin_svc_params = {'C' : [0.1, 0.5, 0.7, 1.0, 2.0, 5.0],\n",
    "                  'penalty' : ['l1', 'l2'],\n",
    "                  'dual' : [False],\n",
    "                  'random_state' : [35]}\n",
    "n_iter_search = 25"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Get the list of pitcher ids to loop through\n",
    "pitcher_list = test['pitcher'].values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "#Initialize the dictionaries to hold the results\n",
    "rf_dict = {}\n",
    "gbm_dict = {}\n",
    "log_dict = {}\n",
    "lin_svc_dict = {}\n",
    "\n",
    "#Run through the pitchers\n",
    "for pitcher in pitcher_list:\n",
    "    \n",
    "    #Get the pitchers data\n",
    "    try:\n",
    "        pitcher_df = get_pitcher_df_for_modeling(cur, \n",
    "                                pitcher_id = pitcher, \n",
    "                                date_subsetting = False)\n",
    "    except:\n",
    "        # Establish a connection to the redshift database\n",
    "        conn = create_rs_conn(config=REDSHIFT_CONFIG)\n",
    "        cur = conn.cursor()\n",
    "        \n",
    "        #Retry on the pitchers\n",
    "        pitcher_df = get_pitcher_df_for_modeling(cur, \n",
    "                                pitcher_id = pitcher, \n",
    "                                date_subsetting = False)\n",
    "    \n",
    "    #Sort the dataframe and create a 90-10 split by date\n",
    "    subset_date = str(pitcher_df['date'].quantile(.9))[:10]\n",
    "    modeling_data = split_test_train(pitcher_df, subset_date)\n",
    "    \n",
    "    #Subset down to the columns of interest\n",
    "    baseline_dict = subset_data(modeling_data, cols_of_interest)\n",
    "\n",
    "    #Random Search over 4 different classifiers\n",
    "    rf_dict[pitcher] = run_randomsearch_classifier2(RandomizedSearchCV(RandomForestClassifier(),\n",
    "                                                                 param_distributions = rf_params,\n",
    "                                                                 n_iter = n_iter_search),\n",
    "                                              baseline_dict)\n",
    "\n",
    "    gbm_dict[pitcher] = run_randomsearch_classifier2(RandomizedSearchCV(GradientBoostingClassifier(),\n",
    "                                                                 param_distributions = gbm_params,\n",
    "                                                                 n_iter = n_iter_search),\n",
    "                                              baseline_dict)\n",
    "\n",
    "    log_dict[pitcher] = run_randomsearch_classifier2(RandomizedSearchCV(LogisticRegression(),\n",
    "                                                                 param_distributions = log_params,\n",
    "                                                                 n_iter = n_iter_search),\n",
    "                                              baseline_dict)\n",
    "\n",
    "    lin_svc_dict[pitcher] = run_randomsearch_classifier2(RandomizedSearchCV(LinearSVC(),\n",
    "                                                                 param_distributions = lin_svc_params,\n",
    "                                                                 n_iter = n_iter_search),\n",
    "                                              baseline_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "rf_dict = {450729: {'accuracy': 0.80372250423011848,\n",
    "  'baseline_accuracy': 0.702,\n",
    "  'params': {'max_depth': 3,\n",
    "   'max_features': 'auto',\n",
    "   'min_samples_leaf': 10,\n",
    "   'min_samples_split': 6,\n",
    "   'n_estimators': 50,\n",
    "   'random_state': 35}},\n",
    " 451661: {'accuracy': 0.71162790697674416,\n",
    "  'baseline_accuracy': 0.701,\n",
    "  'params': {'max_depth': 3,\n",
    "   'max_features': 'auto',\n",
    "   'min_samples_leaf': 10,\n",
    "   'min_samples_split': 10,\n",
    "   'n_estimators': 500,\n",
    "   'random_state': 35}},\n",
    " 493159: {'accuracy': 0.71359223300970875,\n",
    "  'baseline_accuracy': 0.585,\n",
    "  'params': {'max_depth': 3,\n",
    "   'max_features': 'auto',\n",
    "   'min_samples_leaf': 8,\n",
    "   'min_samples_split': 7,\n",
    "   'n_estimators': 50,\n",
    "   'random_state': 35}},\n",
    " 501822: {'accuracy': 0.78500000000000003,\n",
    "  'baseline_accuracy': 0.649,\n",
    "  'params': {'max_depth': 3,\n",
    "   'max_features': 'auto',\n",
    "   'min_samples_leaf': 8,\n",
    "   'min_samples_split': 1,\n",
    "   'n_estimators': 350,\n",
    "   'random_state': 35}},\n",
    " 523989: {'accuracy': 0.63148148148148153,\n",
    "  'baseline_accuracy': 0.646,\n",
    "  'params': {'max_depth': 3,\n",
    "   'max_features': 'auto',\n",
    "   'min_samples_leaf': 8,\n",
    "   'min_samples_split': 6,\n",
    "   'n_estimators': 500,\n",
    "   'random_state': 35}},\n",
    " 527048: {'accuracy': 0.61864406779661019,\n",
    "  'baseline_accuracy': 0.595,\n",
    "  'params': {'max_depth': 3,\n",
    "   'max_features': 'auto',\n",
    "   'min_samples_leaf': 2,\n",
    "   'min_samples_split': 9,\n",
    "   'n_estimators': 150,\n",
    "   'random_state': 35}},\n",
    " 533167: {'accuracy': 0.61007957559681703,\n",
    "  'baseline_accuracy': 0.51,\n",
    "  'params': {'max_depth': 3,\n",
    "   'max_features': 'auto',\n",
    "   'min_samples_leaf': 7,\n",
    "   'min_samples_split': 10,\n",
    "   'n_estimators': 50,\n",
    "   'random_state': 35}},\n",
    " 547888: {'accuracy': 0.69009584664536738,\n",
    "  'baseline_accuracy': 0.722,\n",
    "  'params': {'max_depth': 3,\n",
    "   'max_features': None,\n",
    "   'min_samples_leaf': 8,\n",
    "   'min_samples_split': 5,\n",
    "   'n_estimators': 50,\n",
    "   'random_state': 35}},\n",
    " 573204: {'accuracy': 0.71604938271604934,\n",
    "  'baseline_accuracy': 0.656,\n",
    "  'params': {'max_depth': 3,\n",
    "   'max_features': None,\n",
    "   'min_samples_leaf': 10,\n",
    "   'min_samples_split': 9,\n",
    "   'n_estimators': 10,\n",
    "   'random_state': 35}},\n",
    " 595307: {'accuracy': 0.64552238805970152,\n",
    "  'baseline_accuracy': 0.706,\n",
    "  'params': {'max_depth': 3,\n",
    "   'max_features': 'auto',\n",
    "   'min_samples_leaf': 9,\n",
    "   'min_samples_split': 2,\n",
    "   'n_estimators': 500,\n",
    "   'random_state': 35}}}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([450729, 451661, 493159, 501822, 523989, 527048, 533167, 547888,\n",
       "       573204, 595307], dtype=int64)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pitcher_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "accuracy_dict = {}\n",
    "pitcher = pitcher_list[0]\n",
    "\n",
    "accuracy_dict[pitcher] = {}\n",
    "try:\n",
    "    pitcher_df = get_pitcher_df_for_modeling(cur, \n",
    "                            pitcher_id = pitcher, \n",
    "                            date_subsetting = False)\n",
    "except:\n",
    "    # Establish a connection to the redshift database\n",
    "    conn = create_rs_conn(config=REDSHIFT_CONFIG)\n",
    "    cur = conn.cursor()\n",
    "\n",
    "    #Retry on the pitchers\n",
    "    pitcher_df = get_pitcher_df_for_modeling(cur, \n",
    "                            pitcher_id = pitcher, \n",
    "                            date_subsetting = False)\n",
    "\n",
    "#Sort the dataframe and create a 90-10 split by date\n",
    "subset_date = str(pitcher_df['date'].quantile(.9))[:10]\n",
    "modeling_data = split_test_train(pitcher_df, subset_date)\n",
    "\n",
    "#Subset down to the columns of interest\n",
    "baseline_dict = subset_data(modeling_data, cols_of_interest)\n",
    "\n",
    "accuracy_list = []\n",
    "diff_from_best = []\n",
    "print 'naive_accuracy:', rf_dict[pitcher]['baseline_accuracy']\n",
    "print 'best_accuracy:', rf_dict[pitcher]['accuracy']\n",
    "for new_pitcher in pitcher_list:\n",
    "    rf_test = RandomForestClassifier(min_samples_leaf= rf_dict[new_pitcher]['params']['min_samples_leaf'], \n",
    "                                     min_samples_split=rf_dict[new_pitcher]['params']['min_samples_split'],\n",
    "                                     n_estimators=rf_dict[new_pitcher]['params']['n_estimators'])\n",
    "    new_acc = run_classifier(rf_test, baseline_dict)\n",
    "    accuracy_list.append(new_acc)\n",
    "    diff_from_best.append(new_acc - rf_dict[pitcher]['accuracy'])\n",
    "\n",
    "print 'Acc. list:', accuracy_list\n",
    "print 'Acc. Mean:', pd.Series(accuracy_list).mean()\n",
    "print 'Acc. SD:', pd.Series(accuracy_list).std()\n",
    "print 'Acc. diff list:', diff_from_best\n",
    "print 'Acc. diff Mean:', pd.Series(diff_from_best).mean()\n",
    "print 'Acc. diff SD:', pd.Series(diff_from_best).std()\n",
    "\n",
    "accuracy_dict[pitcher]['acc_list'] = accuracy_list\n",
    "accuracy_dict[pitcher]['acc_mean'] = pd.Series(accuracy_list).mean()\n",
    "accuracy_dict[pitcher]['acc_std'] = pd.Series(accuracy_list).std()\n",
    "accuracy_dict[pitcher]['acc_diff_list'] = diff_from_best\n",
    "accuracy_dict[pitcher]['acc_diff_mean'] = pd.Series(diff_from_best).mean()\n",
    "accuracy_dict[pitcher]['acc_diff_sd'] = pd.Series(diff_from_best).std()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "accuracy_dict = {}\n",
    "for pitcher in pitcher_list:\n",
    "    \n",
    "    print 'starting pitcher', pitcher, '\\n'\n",
    "    \n",
    "    accuracy_dict[pitcher] = {}\n",
    "    \n",
    "    try:\n",
    "        pitcher_df = get_pitcher_df_for_modeling(cur, \n",
    "                                pitcher_id = pitcher, \n",
    "                                date_subsetting = False)\n",
    "    except:\n",
    "        # Establish a connection to the redshift database\n",
    "        conn = create_rs_conn(config=REDSHIFT_CONFIG)\n",
    "        cur = conn.cursor()\n",
    "\n",
    "        #Retry on the pitchers\n",
    "        pitcher_df = get_pitcher_df_for_modeling(cur, \n",
    "                                pitcher_id = pitcher, \n",
    "                                date_subsetting = False)\n",
    "\n",
    "    #Sort the dataframe and create a 90-10 split by date\n",
    "    subset_date = str(pitcher_df['date'].quantile(.9))[:10]\n",
    "    modeling_data = split_test_train(pitcher_df, subset_date)\n",
    "\n",
    "    #Subset down to the columns of interest\n",
    "    baseline_dict = subset_data(modeling_data, cols_of_interest)\n",
    "\n",
    "    accuracy_list = []\n",
    "    diff_from_best = []\n",
    "    print 'naive_accuracy:', rf_dict[pitcher]['baseline_accuracy']\n",
    "    print 'best_accuracy:', rf_dict[pitcher]['accuracy']\n",
    "    for new_pitcher in pitcher_list:\n",
    "        rf_test = RandomForestClassifier(min_samples_leaf= rf_dict[new_pitcher]['params']['min_samples_leaf'], \n",
    "                                         min_samples_split=rf_dict[new_pitcher]['params']['min_samples_split'],\n",
    "                                         n_estimators=rf_dict[new_pitcher]['params']['n_estimators'])\n",
    "        new_acc = run_classifier(rf_test, baseline_dict)\n",
    "        accuracy_list.append(new_acc)\n",
    "        diff_from_best.append(new_acc - rf_dict[pitcher]['accuracy'])\n",
    "\n",
    "    print 'Acc. list:', accuracy_list\n",
    "    print 'Acc. Mean:', pd.Series(accuracy_list).mean()\n",
    "    print 'Acc. SD:', pd.Series(accuracy_list).std()\n",
    "    print 'Acc. diff list:', diff_from_best\n",
    "    print 'Acc. diff Mean:', pd.Series(diff_from_best).mean()\n",
    "    print 'Acc. diff SD:', pd.Series(diff_from_best).std()\n",
    "\n",
    "    accuracy_dict[pitcher]['acc_list'] = accuracy_list\n",
    "    accuracy_dict[pitcher]['acc_mean'] = pd.Series(accuracy_list).mean()\n",
    "    accuracy_dict[pitcher]['acc_std'] = pd.Series(accuracy_list).std()\n",
    "    accuracy_dict[pitcher]['acc_diff_list'] = diff_from_best\n",
    "    accuracy_dict[pitcher]['acc_diff_mean'] = pd.Series(diff_from_best).mean()\n",
    "    accuracy_dict[pitcher]['acc_diff_sd'] = pd.Series(diff_from_best).std()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{450729: {'acc_diff_list': [-0.00056401579244225175,\n",
       "   -0.00056401579244225175,\n",
       "   -0.002256063169768785,\n",
       "   -0.0011280315848843925,\n",
       "   0.0,\n",
       "   -0.0090242526790750288,\n",
       "   0.0,\n",
       "   -0.002256063169768785,\n",
       "   -0.021432600112803235,\n",
       "   -0.0011280315848843925],\n",
       "  'acc_diff_mean': -0.0038353073886069123,\n",
       "  'acc_diff_sd': 0.0067252297486844661,\n",
       "  'acc_list': [0.80315848843767623,\n",
       "   0.80315848843767623,\n",
       "   0.8014664410603497,\n",
       "   0.80259447264523409,\n",
       "   0.80372250423011848,\n",
       "   0.79469825155104346,\n",
       "   0.80372250423011848,\n",
       "   0.8014664410603497,\n",
       "   0.78228990411731525,\n",
       "   0.80259447264523409],\n",
       "  'acc_mean': 0.79988719684151166,\n",
       "  'acc_std': 0.0067252297486780008},\n",
       " 451661: {'acc_diff_list': [-0.009302325581395321,\n",
       "   -0.013953488372092981,\n",
       "   0.013953488372093092,\n",
       "   -0.013953488372092981,\n",
       "   -0.009302325581395321,\n",
       "   0.0046511627906976605,\n",
       "   -0.013953488372092981,\n",
       "   0.0,\n",
       "   -0.013953488372092981,\n",
       "   0.0046511627906976605],\n",
       "  'acc_diff_mean': -0.0051162790697674154,\n",
       "  'acc_diff_sd': 0.010154742879883908,\n",
       "  'acc_list': [0.70232558139534884,\n",
       "   0.69767441860465118,\n",
       "   0.72558139534883725,\n",
       "   0.69767441860465118,\n",
       "   0.70232558139534884,\n",
       "   0.71627906976744182,\n",
       "   0.69767441860465118,\n",
       "   0.71162790697674416,\n",
       "   0.69767441860465118,\n",
       "   0.71627906976744182],\n",
       "  'acc_mean': 0.70651162790697675,\n",
       "  'acc_std': 0.010154742879890941},\n",
       " 493159: {'acc_diff_list': [-0.038834951456310662,\n",
       "   0.0048543689320388328,\n",
       "   -0.0097087378640776656,\n",
       "   0.0,\n",
       "   0.0097087378640776656,\n",
       "   -0.024271844660194164,\n",
       "   0.014563106796116498,\n",
       "   -0.029126213592232997,\n",
       "   -0.08737864077669899,\n",
       "   0.0],\n",
       "  'acc_diff_mean': -0.016019417475728149,\n",
       "  'acc_diff_sd': 0.030620599233050671,\n",
       "  'acc_list': [0.67475728155339809,\n",
       "   0.71844660194174759,\n",
       "   0.70388349514563109,\n",
       "   0.71359223300970875,\n",
       "   0.72330097087378642,\n",
       "   0.68932038834951459,\n",
       "   0.72815533980582525,\n",
       "   0.68446601941747576,\n",
       "   0.62621359223300976,\n",
       "   0.71359223300970875],\n",
       "  'acc_mean': 0.69757281553398065,\n",
       "  'acc_std': 0.030620599233050834},\n",
       " 501822: {'acc_diff_list': [-0.010000000000000009,\n",
       "   -0.0050000000000000044,\n",
       "   -0.040000000000000036,\n",
       "   0.0050000000000000044,\n",
       "   -0.015000000000000013,\n",
       "   -0.0050000000000000044,\n",
       "   -0.030000000000000027,\n",
       "   -0.015000000000000013,\n",
       "   -0.030000000000000027,\n",
       "   0.0],\n",
       "  'acc_diff_mean': -0.014500000000000013,\n",
       "  'acc_diff_sd': 0.014615440845595851,\n",
       "  'acc_list': [0.77500000000000002,\n",
       "   0.78000000000000003,\n",
       "   0.745,\n",
       "   0.79000000000000004,\n",
       "   0.77000000000000002,\n",
       "   0.78000000000000003,\n",
       "   0.755,\n",
       "   0.77000000000000002,\n",
       "   0.755,\n",
       "   0.78500000000000003],\n",
       "  'acc_mean': 0.77050000000000007,\n",
       "  'acc_std': 0.014615440845596022},\n",
       " 523989: {'acc_diff_list': [-0.0037037037037037646,\n",
       "   0.0018518518518517713,\n",
       "   -0.018518518518518601,\n",
       "   0.0037037037037036535,\n",
       "   -0.011111111111111183,\n",
       "   -0.020370370370370372,\n",
       "   -0.0055555555555556468,\n",
       "   -0.0092592592592593004,\n",
       "   -0.011111111111111183,\n",
       "   0.0037037037037036535],\n",
       "  'acc_diff_mean': -0.0070370370370370968,\n",
       "  'acc_diff_sd': 0.0086331524627392964,\n",
       "  'acc_list': [0.62777777777777777,\n",
       "   0.6333333333333333,\n",
       "   0.61296296296296293,\n",
       "   0.63518518518518519,\n",
       "   0.62037037037037035,\n",
       "   0.61111111111111116,\n",
       "   0.62592592592592589,\n",
       "   0.62222222222222223,\n",
       "   0.62037037037037035,\n",
       "   0.63518518518518519],\n",
       "  'acc_mean': 0.62444444444444447,\n",
       "  'acc_std': 0.008633152462741862},\n",
       " 527048: {'acc_diff_list': [-0.019774011299435013,\n",
       "   0.0,\n",
       "   -0.042372881355932202,\n",
       "   -0.014124293785310771,\n",
       "   -0.0056497175141243527,\n",
       "   -0.022598870056497189,\n",
       "   -0.033898305084745783,\n",
       "   -0.025423728813559365,\n",
       "   -0.042372881355932202,\n",
       "   -0.019774011299435013],\n",
       "  'acc_diff_mean': -0.022598870056497189,\n",
       "  'acc_diff_sd': 0.014155646307319114,\n",
       "  'acc_list': [0.59887005649717517,\n",
       "   0.61864406779661019,\n",
       "   0.57627118644067798,\n",
       "   0.60451977401129942,\n",
       "   0.61299435028248583,\n",
       "   0.596045197740113,\n",
       "   0.5847457627118644,\n",
       "   0.59322033898305082,\n",
       "   0.57627118644067798,\n",
       "   0.59887005649717517],\n",
       "  'acc_mean': 0.596045197740113,\n",
       "  'acc_std': 0.014155646307319632},\n",
       " 533167: {'acc_diff_list': [-0.045092838196286511,\n",
       "   -0.047745358090185763,\n",
       "   -0.045092838196286511,\n",
       "   -0.045092838196286511,\n",
       "   -0.045092838196286511,\n",
       "   -0.050397877984084904,\n",
       "   -0.037135278514588865,\n",
       "   -0.045092838196286511,\n",
       "   -0.04244031830238737,\n",
       "   -0.031830238726790472],\n",
       "  'acc_diff_mean': -0.043501326259946994,\n",
       "  'acc_diff_sd': 0.0053344308148534714,\n",
       "  'acc_list': [0.56498673740053051,\n",
       "   0.56233421750663126,\n",
       "   0.56498673740053051,\n",
       "   0.56498673740053051,\n",
       "   0.56498673740053051,\n",
       "   0.55968169761273212,\n",
       "   0.57294429708222816,\n",
       "   0.56498673740053051,\n",
       "   0.56763925729442966,\n",
       "   0.57824933687002655],\n",
       "  'acc_mean': 0.56657824933687007,\n",
       "  'acc_std': 0.0053344308148447275},\n",
       " 547888: {'acc_diff_list': [0.0,\n",
       "   0.0,\n",
       "   -0.012779552715654896,\n",
       "   -0.012779552715654896,\n",
       "   -0.006389776357827448,\n",
       "   -0.006389776357827448,\n",
       "   -0.0031948881789136685,\n",
       "   0.006389776357827559,\n",
       "   -0.031948881789137351,\n",
       "   -0.0031948881789136685],\n",
       "  'acc_diff_mean': -0.0070287539936101815,\n",
       "  'acc_diff_sd': 0.010521055621067921,\n",
       "  'acc_list': [0.69009584664536738,\n",
       "   0.69009584664536738,\n",
       "   0.67731629392971249,\n",
       "   0.67731629392971249,\n",
       "   0.68370607028753994,\n",
       "   0.68370607028753994,\n",
       "   0.68690095846645371,\n",
       "   0.69648562300319494,\n",
       "   0.65814696485623003,\n",
       "   0.68690095846645371],\n",
       "  'acc_mean': 0.68306709265175714,\n",
       "  'acc_std': 0.01052105562107054},\n",
       " 573204: {'acc_diff_list': [-0.030864197530864113,\n",
       "   -0.037037037037036979,\n",
       "   -0.037037037037036979,\n",
       "   -0.049382716049382713,\n",
       "   -0.067901234567901203,\n",
       "   -0.043209876543209846,\n",
       "   -0.01851851851851849,\n",
       "   -0.01851851851851849,\n",
       "   -0.030864197530864113,\n",
       "   -0.07407407407407407],\n",
       "  'acc_diff_mean': -0.040740740740740702,\n",
       "  'acc_diff_sd': 0.018677869494502432,\n",
       "  'acc_list': [0.68518518518518523,\n",
       "   0.67901234567901236,\n",
       "   0.67901234567901236,\n",
       "   0.66666666666666663,\n",
       "   0.64814814814814814,\n",
       "   0.6728395061728395,\n",
       "   0.69753086419753085,\n",
       "   0.69753086419753085,\n",
       "   0.68518518518518523,\n",
       "   0.64197530864197527],\n",
       "  'acc_mean': 0.6753086419753086,\n",
       "  'acc_std': 0.018677869494503032},\n",
       " 595307: {'acc_diff_list': [-0.014925373134328401,\n",
       "   0.0074626865671642006,\n",
       "   -0.0074626865671642006,\n",
       "   0.0,\n",
       "   0.0074626865671642006,\n",
       "   0.0074626865671642006,\n",
       "   -0.0037313432835821558,\n",
       "   -0.0037313432835821558,\n",
       "   -0.018656716417910446,\n",
       "   0.0074626865671642006],\n",
       "  'acc_diff_mean': -0.0018656716417910558,\n",
       "  'acc_diff_sd': 0.0096743465087711922,\n",
       "  'acc_list': [0.63059701492537312,\n",
       "   0.65298507462686572,\n",
       "   0.63805970149253732,\n",
       "   0.64552238805970152,\n",
       "   0.65298507462686572,\n",
       "   0.65298507462686572,\n",
       "   0.64179104477611937,\n",
       "   0.64179104477611937,\n",
       "   0.62686567164179108,\n",
       "   0.65298507462686572],\n",
       "  'acc_mean': 0.64365671641791045,\n",
       "  'acc_std': 0.0096743465087695182}}"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "gbm_dict = {450729: {'accuracy': 0.80372250423011848,\n",
    "  'baseline_accuracy': 0.702,\n",
    "  'params': {'loss': 'deviance',\n",
    "   'max_depth': 3,\n",
    "   'max_features': 'auto',\n",
    "   'min_samples_leaf': 6,\n",
    "   'min_samples_split': 6,\n",
    "   'n_estimators': 10,\n",
    "   'random_state': 35}},\n",
    " 451661: {'accuracy': 0.71627906976744182,\n",
    "  'baseline_accuracy': 0.701,\n",
    "  'params': {'loss': 'deviance',\n",
    "   'max_depth': 3,\n",
    "   'max_features': None,\n",
    "   'min_samples_leaf': 9,\n",
    "   'min_samples_split': 3,\n",
    "   'n_estimators': 10,\n",
    "   'random_state': 35}},\n",
    " 493159: {'accuracy': 0.62621359223300976,\n",
    "  'baseline_accuracy': 0.585,\n",
    "  'params': {'loss': 'deviance',\n",
    "   'max_depth': None,\n",
    "   'max_features': 'auto',\n",
    "   'min_samples_leaf': 3,\n",
    "   'min_samples_split': 8,\n",
    "   'n_estimators': 100,\n",
    "   'random_state': 35}},\n",
    " 501822: {'accuracy': 0.76500000000000001,\n",
    "  'baseline_accuracy': 0.649,\n",
    "  'params': {'loss': 'deviance',\n",
    "   'max_depth': 3,\n",
    "   'max_features': None,\n",
    "   'min_samples_leaf': 8,\n",
    "   'min_samples_split': 4,\n",
    "   'n_estimators': 10,\n",
    "   'random_state': 35}},\n",
    " 523989: {'accuracy': 0.63148148148148153,\n",
    "  'baseline_accuracy': 0.646,\n",
    "  'params': {'loss': 'deviance',\n",
    "   'max_depth': 3,\n",
    "   'max_features': None,\n",
    "   'min_samples_leaf': 8,\n",
    "   'min_samples_split': 10,\n",
    "   'n_estimators': 10,\n",
    "   'random_state': 35}},\n",
    " 527048: {'accuracy': 0.61581920903954801,\n",
    "  'baseline_accuracy': 0.595,\n",
    "  'params': {'loss': 'deviance',\n",
    "   'max_depth': 3,\n",
    "   'max_features': None,\n",
    "   'min_samples_leaf': 5,\n",
    "   'min_samples_split': 7,\n",
    "   'n_estimators': 100,\n",
    "   'random_state': 35}},\n",
    " 533167: {'accuracy': 0.51193633952254647,\n",
    "  'baseline_accuracy': 0.51,\n",
    "  'params': {'loss': 'deviance',\n",
    "   'max_depth': None,\n",
    "   'max_features': 'auto',\n",
    "   'min_samples_leaf': 8,\n",
    "   'min_samples_split': 6,\n",
    "   'n_estimators': 250,\n",
    "   'random_state': 35}},\n",
    " 547888: {'accuracy': 0.69648562300319494,\n",
    "  'baseline_accuracy': 0.722,\n",
    "  'params': {'loss': 'deviance',\n",
    "   'max_depth': 3,\n",
    "   'max_features': 'auto',\n",
    "   'min_samples_leaf': 10,\n",
    "   'min_samples_split': 6,\n",
    "   'n_estimators': 50,\n",
    "   'random_state': 35}},\n",
    " 573204: {'accuracy': 0.66666666666666663,\n",
    "  'baseline_accuracy': 0.656,\n",
    "  'params': {'loss': 'deviance',\n",
    "   'max_depth': None,\n",
    "   'max_features': 'auto',\n",
    "   'min_samples_leaf': 10,\n",
    "   'min_samples_split': 2,\n",
    "   'n_estimators': 10,\n",
    "   'random_state': 35}},\n",
    " 595307: {'accuracy': 0.64925373134328357,\n",
    "  'baseline_accuracy': 0.706,\n",
    "  'params': {'loss': 'deviance',\n",
    "   'max_depth': 3,\n",
    "   'max_features': None,\n",
    "   'min_samples_leaf': 4,\n",
    "   'min_samples_split': 3,\n",
    "   'n_estimators': 10,\n",
    "   'random_state': 35}}}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "gbm_accuracy_dict = {}\n",
    "for pitcher in pitcher_list:\n",
    "    \n",
    "    print 'starting pitcher', pitcher, '\\n'\n",
    "    \n",
    "    gbm_accuracy_dict[pitcher] = {}\n",
    "    \n",
    "    try:\n",
    "        pitcher_df = get_pitcher_df_for_modeling(cur, \n",
    "                                pitcher_id = pitcher, \n",
    "                                date_subsetting = False)\n",
    "    except:\n",
    "        # Establish a connection to the redshift database\n",
    "        conn = create_rs_conn(config=REDSHIFT_CONFIG)\n",
    "        cur = conn.cursor()\n",
    "\n",
    "        #Retry on the pitchers\n",
    "        pitcher_df = get_pitcher_df_for_modeling(cur, \n",
    "                                pitcher_id = pitcher, \n",
    "                                date_subsetting = False)\n",
    "\n",
    "    #Sort the dataframe and create a 90-10 split by date\n",
    "    subset_date = str(pitcher_df['date'].quantile(.9))[:10]\n",
    "    modeling_data = split_test_train(pitcher_df, subset_date)\n",
    "\n",
    "    #Subset down to the columns of interest\n",
    "    baseline_dict = subset_data(modeling_data, cols_of_interest)\n",
    "\n",
    "    accuracy_list = []\n",
    "    diff_from_best = []\n",
    "    print 'naive_accuracy:', gbm_dict[pitcher]['baseline_accuracy']\n",
    "    print 'best_accuracy:', gbm_dict[pitcher]['accuracy']\n",
    "    gbm_accuracy_dict[pitcher]['best_acc'] = gbm_dict[pitcher]['baseline_accuracy']\n",
    "    gbm_accuracy_dict[pitcher]['naive_acc'] = gbm_dict[pitcher]['accuracy']\n",
    "    \n",
    "    for new_pitcher in pitcher_list:\n",
    "        rf_test = GradientBoostingClassifier(min_samples_leaf= gbm_dict[new_pitcher]['params']['min_samples_leaf'], \n",
    "                                         min_samples_split=gbm_dict[new_pitcher]['params']['min_samples_split'],\n",
    "                                         n_estimators=gbm_dict[new_pitcher]['params']['n_estimators'])\n",
    "        new_acc = run_classifier(rf_test, baseline_dict)\n",
    "        accuracy_list.append(new_acc)\n",
    "        diff_from_best.append(new_acc - gbm_dict[pitcher]['accuracy'])\n",
    "\n",
    "    print 'Acc. list:', accuracy_list\n",
    "    print 'Acc. Mean:', pd.Series(accuracy_list).mean()\n",
    "    print 'Acc. SD:', pd.Series(accuracy_list).std()\n",
    "    print 'Acc. diff list:', diff_from_best\n",
    "    print 'Acc. diff Mean:', pd.Series(diff_from_best).mean()\n",
    "    print 'Acc. diff SD:', pd.Series(diff_from_best).std()\n",
    "    \n",
    "    gbm_accuracy_dict[pitcher]['acc_list'] = accuracy_list\n",
    "    gbm_accuracy_dict[pitcher]['acc_mean'] = pd.Series(accuracy_list).mean()\n",
    "    gbm_accuracy_dict[pitcher]['acc_std'] = pd.Series(accuracy_list).std()\n",
    "    gbm_accuracy_dict[pitcher]['acc_diff_list'] = diff_from_best\n",
    "    gbm_accuracy_dict[pitcher]['acc_diff_mean'] = pd.Series(diff_from_best).mean()\n",
    "    gbm_accuracy_dict[pitcher]['acc_diff_sd'] = pd.Series(diff_from_best).std()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "log_dict = {450729: {'accuracy': 0.80259447264523409,\n",
    "  'baseline_accuracy': 0.702,\n",
    "  'params': {'C': 0.1, 'penalty': 'l1', 'random_state': 35}},\n",
    " 451661: {'accuracy': 0.71627906976744182,\n",
    "  'baseline_accuracy': 0.701,\n",
    "  'params': {'C': 0.1, 'penalty': 'l1', 'random_state': 35}},\n",
    " 493159: {'accuracy': 0.62135922330097082,\n",
    "  'baseline_accuracy': 0.585,\n",
    "  'params': {'C': 0.1, 'penalty': 'l1', 'random_state': 35}},\n",
    " 501822: {'accuracy': 0.78000000000000003,\n",
    "  'baseline_accuracy': 0.649,\n",
    "  'params': {'C': 0.1, 'penalty': 'l1', 'random_state': 35}},\n",
    " 523989: {'accuracy': 0.63148148148148153,\n",
    "  'baseline_accuracy': 0.646,\n",
    "  'params': {'C': 0.1, 'penalty': 'l1', 'random_state': 35}},\n",
    " 527048: {'accuracy': 0.596045197740113,\n",
    "  'baseline_accuracy': 0.595,\n",
    "  'params': {'C': 7.0, 'penalty': 'l1', 'random_state': 35}},\n",
    " 533167: {'accuracy': 0.61273209549071617,\n",
    "  'baseline_accuracy': 0.51,\n",
    "  'params': {'C': 1.0, 'penalty': 'l2', 'random_state': 35}},\n",
    " 547888: {'accuracy': 0.69009584664536738,\n",
    "  'baseline_accuracy': 0.722,\n",
    "  'params': {'C': 0.1, 'penalty': 'l2', 'random_state': 35}},\n",
    " 573204: {'accuracy': 0.66666666666666663,\n",
    "  'baseline_accuracy': 0.656,\n",
    "  'params': {'C': 0.5, 'penalty': 'l1', 'random_state': 35}},\n",
    " 595307: {'accuracy': 0.58582089552238803,\n",
    "  'baseline_accuracy': 0.706,\n",
    "  'params': {'C': 1.0, 'penalty': 'l2', 'random_state': 35}}}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "log_accuracy_dict = {}\n",
    "for pitcher in pitcher_list:\n",
    "    \n",
    "    print 'starting pitcher', pitcher, '\\n'\n",
    "    \n",
    "    log_accuracy_dict[pitcher] = {}\n",
    "    \n",
    "    try:\n",
    "        pitcher_df = get_pitcher_df_for_modeling(cur, \n",
    "                                pitcher_id = pitcher, \n",
    "                                date_subsetting = False)\n",
    "    except:\n",
    "        # Establish a connection to the redshift database\n",
    "        conn = create_rs_conn(config=REDSHIFT_CONFIG)\n",
    "        cur = conn.cursor()\n",
    "\n",
    "        #Retry on the pitchers\n",
    "        pitcher_df = get_pitcher_df_for_modeling(cur, \n",
    "                                pitcher_id = pitcher, \n",
    "                                date_subsetting = False)\n",
    "\n",
    "    #Sort the dataframe and create a 90-10 split by date\n",
    "    subset_date = str(pitcher_df['date'].quantile(.9))[:10]\n",
    "    modeling_data = split_test_train(pitcher_df, subset_date)\n",
    "\n",
    "    #Subset down to the columns of interest\n",
    "    baseline_dict = subset_data(modeling_data, cols_of_interest)\n",
    "\n",
    "    accuracy_list = []\n",
    "    diff_from_best = []\n",
    "    print 'naive_accuracy:', log_dict[pitcher]['baseline_accuracy']\n",
    "    print 'best_accuracy:', log_dict[pitcher]['accuracy']\n",
    "    log_accuracy_dict[pitcher]['best_acc'] = log_dict[pitcher]['baseline_accuracy']\n",
    "    log_accuracy_dict[pitcher]['naive_acc'] = log_dict[pitcher]['accuracy']\n",
    "    \n",
    "    for new_pitcher in pitcher_list:\n",
    "        rf_test = LogisticRegression(C= log_dict[new_pitcher]['params']['C'], \n",
    "                                         penalty=log_dict[new_pitcher]['params']['penalty'],\n",
    "                                         random_state = 35)\n",
    "        new_acc = run_classifier(rf_test, baseline_dict)\n",
    "        accuracy_list.append(new_acc)\n",
    "        diff_from_best.append(new_acc - log_dict[pitcher]['accuracy'])\n",
    "\n",
    "    print 'Acc. list:', accuracy_list\n",
    "    print 'Acc. Mean:', pd.Series(accuracy_list).mean()\n",
    "    print 'Acc. SD:', pd.Series(accuracy_list).std()\n",
    "    print 'Acc. diff list:', diff_from_best\n",
    "    print 'Acc. diff Mean:', pd.Series(diff_from_best).mean()\n",
    "    print 'Acc. diff SD:', pd.Series(diff_from_best).std()\n",
    "    \n",
    "    log_accuracy_dict[pitcher]['acc_list'] = accuracy_list\n",
    "    log_accuracy_dict[pitcher]['acc_mean'] = pd.Series(accuracy_list).mean()\n",
    "    log_accuracy_dict[pitcher]['acc_std'] = pd.Series(accuracy_list).std()\n",
    "    log_accuracy_dict[pitcher]['acc_diff_list'] = diff_from_best\n",
    "    log_accuracy_dict[pitcher]['acc_diff_mean'] = pd.Series(diff_from_best).mean()\n",
    "    log_accuracy_dict[pitcher]['acc_diff_sd'] = pd.Series(diff_from_best).std()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "lin_svc_dict = {450729: {'accuracy': 0.80428652002256062,\n",
    "  'baseline_accuracy': 0.702,\n",
    "  'params': {'C': 1.0, 'dual': False, 'penalty': 'l2', 'random_state': 35}},\n",
    " 451661: {'accuracy': 0.71627906976744182,\n",
    "  'baseline_accuracy': 0.701,\n",
    "  'params': {'C': 0.1, 'dual': False, 'penalty': 'l2', 'random_state': 35}},\n",
    " 493159: {'accuracy': 0.64563106796116509,\n",
    "  'baseline_accuracy': 0.585,\n",
    "  'params': {'C': 0.1, 'dual': False, 'penalty': 'l1', 'random_state': 35}},\n",
    " 501822: {'accuracy': 0.78500000000000003,\n",
    "  'baseline_accuracy': 0.649,\n",
    "  'params': {'C': 1.0, 'dual': False, 'penalty': 'l1', 'random_state': 35}},\n",
    " 523989: {'accuracy': 0.62592592592592589,\n",
    "  'baseline_accuracy': 0.646,\n",
    "  'params': {'C': 0.1, 'dual': False, 'penalty': 'l1', 'random_state': 35}},\n",
    " 527048: {'accuracy': 0.58757062146892658,\n",
    "  'baseline_accuracy': 0.595,\n",
    "  'params': {'C': 5.0, 'dual': False, 'penalty': 'l2', 'random_state': 35}},\n",
    " 533167: {'accuracy': 0.60742705570291777,\n",
    "  'baseline_accuracy': 0.51,\n",
    "  'params': {'C': 0.1, 'dual': False, 'penalty': 'l1', 'random_state': 35}},\n",
    " 547888: {'accuracy': 0.68690095846645371,\n",
    "  'baseline_accuracy': 0.722,\n",
    "  'params': {'C': 0.1, 'dual': False, 'penalty': 'l1', 'random_state': 35}},\n",
    " 573204: {'accuracy': 0.66666666666666663,\n",
    "  'baseline_accuracy': 0.656,\n",
    "  'params': {'C': 2.0, 'dual': False, 'penalty': 'l1', 'random_state': 35}},\n",
    " 595307: {'accuracy': 0.58208955223880599,\n",
    "  'baseline_accuracy': 0.706,\n",
    "  'params': {'C': 0.1, 'dual': False, 'penalty': 'l2', 'random_state': 35}}}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "lin_svc_accuracy_dict = {}\n",
    "for pitcher in pitcher_list:\n",
    "    \n",
    "    print 'starting pitcher', pitcher, '\\n'\n",
    "    \n",
    "    lin_svc_accuracy_dict[pitcher] = {}\n",
    "    \n",
    "    try:\n",
    "        pitcher_df = get_pitcher_df_for_modeling(cur, \n",
    "                                pitcher_id = pitcher, \n",
    "                                date_subsetting = False)\n",
    "    except:\n",
    "        # Establish a connection to the redshift database\n",
    "        conn = create_rs_conn(config=REDSHIFT_CONFIG)\n",
    "        cur = conn.cursor()\n",
    "\n",
    "        #Retry on the pitchers\n",
    "        pitcher_df = get_pitcher_df_for_modeling(cur, \n",
    "                                pitcher_id = pitcher, \n",
    "                                date_subsetting = False)\n",
    "\n",
    "    #Sort the dataframe and create a 90-10 split by date\n",
    "    subset_date = str(pitcher_df['date'].quantile(.9))[:10]\n",
    "    modeling_data = split_test_train(pitcher_df, subset_date)\n",
    "\n",
    "    #Subset down to the columns of interest\n",
    "    baseline_dict = subset_data(modeling_data, cols_of_interest)\n",
    "\n",
    "    accuracy_list = []\n",
    "    diff_from_best = []\n",
    "    print 'naive_accuracy:', lin_svc_dict[pitcher]['baseline_accuracy']\n",
    "    print 'best_accuracy:', lin_svc_dict[pitcher]['accuracy']\n",
    "    lin_svc_accuracy_dict[pitcher]['best_acc'] = lin_svc_dict[pitcher]['baseline_accuracy']\n",
    "    lin_svc_accuracy_dict[pitcher]['naive_acc'] = lin_svc_dict[pitcher]['accuracy']\n",
    "    \n",
    "    for new_pitcher in pitcher_list:\n",
    "        rf_test = LinearSVC(C= lin_svc_dict[new_pitcher]['params']['C'], \n",
    "                                         penalty=lin_svc_dict[new_pitcher]['params']['penalty'],\n",
    "                                         dual = False,\n",
    "                                         random_state = 35)\n",
    "        new_acc = run_classifier(rf_test, baseline_dict)\n",
    "        accuracy_list.append(new_acc)\n",
    "        diff_from_best.append(new_acc - lin_svc_dict[pitcher]['accuracy'])\n",
    "\n",
    "    print 'Acc. list:', accuracy_list\n",
    "    print 'Acc. Mean:', pd.Series(accuracy_list).mean()\n",
    "    print 'Acc. SD:', pd.Series(accuracy_list).std()\n",
    "    print 'Acc. diff list:', diff_from_best\n",
    "    print 'Acc. diff Mean:', pd.Series(diff_from_best).mean()\n",
    "    print 'Acc. diff SD:', pd.Series(diff_from_best).std()\n",
    "    \n",
    "    lin_svc_accuracy_dict[pitcher]['acc_list'] = accuracy_list\n",
    "    lin_svc_accuracy_dict[pitcher]['acc_mean'] = pd.Series(accuracy_list).mean()\n",
    "    lin_svc_accuracy_dict[pitcher]['acc_std'] = pd.Series(accuracy_list).std()\n",
    "    lin_svc_accuracy_dict[pitcher]['acc_diff_list'] = diff_from_best\n",
    "    lin_svc_accuracy_dict[pitcher]['acc_diff_mean'] = pd.Series(diff_from_best).mean()\n",
    "    lin_svc_accuracy_dict[pitcher]['acc_diff_sd'] = pd.Series(diff_from_best).std()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def run_randomsearch_classifier(classifier, data_dict):\n",
    "    \"\"\"Given a classifier and a data dictionary containing 'train_data' and 'test_data' (as pandas DFs),\n",
    "    This runs the classifier and outputs the accuracy of the classifier on the test data.\"\"\"\n",
    "    \n",
    "    # Fit a model on all the data and features\n",
    "    classifier.fit(data_dict['train_data'], data_dict['train_targets'])\n",
    "    \n",
    "    #print the best parameters\n",
    "    print classifier.best_params_\n",
    "\n",
    "    # Make predictions on dev data\n",
    "    dev_predictions = classifier.predict(data_dict['test_data'])\n",
    "    \n",
    "    print accuracy_score(data_dict['test_targets'], dev_predictions)\n",
    "    \n",
    "    # Return the dev performance score.\n",
    "    return dev_predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Hyperparameters don't really matter. We can use a common set for these classifiers. Next up: writing a function that tries all different ensembles and chooses the best combo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pitcher = 595307\n",
    "#Get the pitchers data\n",
    "try:\n",
    "    pitcher_df = get_pitcher_df_for_modeling(cur, \n",
    "                            pitcher_id = pitcher, \n",
    "                            date_subsetting = False)\n",
    "except:\n",
    "    # Establish a connection to the redshift database\n",
    "    conn = create_rs_conn(config=REDSHIFT_CONFIG)\n",
    "    cur = conn.cursor()\n",
    "\n",
    "    #Retry on the pitchers\n",
    "    pitcher_df = get_pitcher_df_for_modeling(cur, \n",
    "                            pitcher_id = pitcher, \n",
    "                            date_subsetting = False)\n",
    "\n",
    "#Sort the dataframe and create a 90-10 split by date\n",
    "subset_date = str(pitcher_df['date'].quantile(.9))[:10]\n",
    "modeling_data = split_test_train(pitcher_df, subset_date)\n",
    "\n",
    "#Subset down to the columns of interest\n",
    "baseline_dict = subset_data(modeling_data, cols_of_interest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def run_all_classifiers(data_dict):\n",
    "    '''Takes in a modeling dictionary and runs the following classifiers:\n",
    "    - Random Forest\n",
    "    - Gradient Boosted Machine\n",
    "    - Logistic Regression\n",
    "    - Linear Support Vector Machine\n",
    "    Returns a dictionary with these four trained models'''\n",
    "    \n",
    "    #Initialize a dictionary to hold all the classifiers\n",
    "    classifier_dict = {}\n",
    "    classifier_dict['rf'] = (RandomForestClassifier(max_depth=3,\n",
    "                                                   min_samples_leaf = 7,\n",
    "                                                   min_samples_split = 6,\n",
    "                                                   n_estimators = 350)\n",
    "                             .fit(data_dict['train_data'], data_dict['train_targets']))\n",
    "    classifier_dict['gbm'] = (GradientBoostingClassifier(max_depth=3,\n",
    "                                                         loss = 'deviance',\n",
    "                                                         max_features = 'auto')\n",
    "                              .fit(data_dict['train_data'], data_dict['train_targets']))\n",
    "    classifier_dict['log_reg'] = (LogisticRegression(C = 0.1,\n",
    "                                                penalty = 'l1')\n",
    "                             .fit(data_dict['train_data'], data_dict['train_targets']))\n",
    "    classifier_dict['lin_svc'] = (LinearSVC(C = 0.1,\n",
    "                                            penalty = 'l1',\n",
    "                                            dual = False)\n",
    "                                  .fit(data_dict['train_data'], data_dict['train_targets']))\n",
    "    \n",
    "    return classifier_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.706"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "naive_accuracy2(baseline_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.642"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "naive_accuracy(baseline_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class_dict = run_all_classifiers(baseline_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.64552238805970152"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(baseline_dict['test_targets'], class_dict['rf'].predict(baseline_dict['test_data']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def collect_classifier_predictions2(data_dict, classifier_dict):\n",
    "    \"\"\"Given a data dictionary  containing 'train_data' and 'test_data' (as pandas DFs) and classifiers (kwargs),\n",
    "    This runs the classifier and outputs the predictions of each classifier as a dictionary.\n",
    "    Input:\n",
    "        data_dict: the data dictionary containing all the train/test data/targets\n",
    "        classifier_dict: dictionary of trained classifiers\n",
    "    Output:\n",
    "        dictionary of predictions where the key is the classifier label given in kwargs and the value is a list of predictions\"\"\"\n",
    "    \n",
    "    pred_dict = {}\n",
    "    for classifier in classifier_dict.keys():\n",
    "\n",
    "        # Make predictions on dev data\n",
    "        pred_dict[classifier] = classifier_dict[classifier].predict(data_dict['test_data'])\n",
    "    \n",
    "    # Return the dev performance score.\n",
    "    return pred_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "prediction_dict = collect_classifier_predictions2(baseline_dict, class_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from itertools import combinations\n",
    "def choose_best_ensemble(pred_dict, modeling_dict):\n",
    "    \n",
    "    #initialize best accuracy\n",
    "    best_accuracy = 0\n",
    "    \n",
    "    #Try each of the classifiers individually\n",
    "    for classifier in pred_dict:\n",
    "        new_acc = accuracy_score(modeling_dict['test_targets'], pred_dict[classifier])\n",
    "        \n",
    "        if new_acc > best_accuracy:\n",
    "            best_accuracy = new_acc\n",
    "            classifier_combo = classifier\n",
    "    \n",
    "    # Using at least three classifiers, try all different modeling combinations\n",
    "    for i in range(3, len(pred_dict.keys()) + 1):\n",
    "        \n",
    "        for combo in combinations(pred_dict.keys(), i):\n",
    "            \n",
    "            #reformulate the pred dictionary based on the current combo\n",
    "            new_dict = dict((k, pred_dict[k]) for k in combo)\n",
    "            \n",
    "            #Ensemble vote\n",
    "            new_preds = ensemble_voting(new_dict)\n",
    "            \n",
    "            #Get accuracy and compare to current best\n",
    "            new_acc = accuracy_score(modeling_dict['test_targets'], new_preds)\n",
    "            if new_acc > best_accuracy:\n",
    "                best_accuracy = new_acc\n",
    "                classifier_combo = combo\n",
    "    \n",
    "    return {'best_acc' : best_accuracy,\n",
    "            'classifier_combination' : classifier_combo}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'best_acc': 0.64552238805970152, 'classifier_combination': 'rf'}"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "choose_best_ensemble(prediction_dict, baseline_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "str"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test = ('hello')\n",
    "type(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "Required argument 'r' (pos 2) not found",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-36-b4ce2c904f29>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mitertools\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[1;33m[\u001b[0m\u001b[0mx\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mitertools\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcombinations\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m3\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m: Required argument 'r' (pos 2) not found"
     ]
    }
   ],
   "source": [
    "import itertools\n",
    "[x for x in itertools.combinations([1,2,3])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def naive_accuracy2(data_dict):\n",
    "    biggest_count = data_dict['train_targets'].value_counts()[0]\n",
    "    all_counts = data_dict['train_targets'].value_counts().sum()\n",
    "    return round(float(biggest_count) / all_counts, 3)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
