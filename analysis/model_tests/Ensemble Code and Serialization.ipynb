{
 "metadata": {
  "name": "",
  "signature": "sha256:9401084fc0ccbabb915e8f7148902a9faf65f1cf524c48d62969ff57b41f1138"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "heading",
     "level": 2,
     "metadata": {},
     "source": [
      "Writing the code with the verlander data"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#Let's get some fake data and implement this piece!\n",
      "import pandas as pd\n",
      "import numpy as np\n",
      "\n",
      "#Get Exploration functions from other folder\n",
      "import sys\n",
      "sys.path.insert(0, '../../src')\n",
      "import exploration\n",
      "\n",
      "#Importing Classifiers\n",
      "from sklearn.neighbors import KNeighborsClassifier\n",
      "from sklearn.naive_bayes import GaussianNB, MultinomialNB\n",
      "from sklearn.tree import DecisionTreeClassifier\n",
      "from sklearn.linear_model import LogisticRegression\n",
      "from sklearn.svm import SVC, LinearSVC\n",
      "from sklearn.ensemble import RandomForestClassifier\n",
      "from sklearn.grid_search import GridSearchCV\n",
      "\n",
      "# SK-learn libraries for evaluation.\n",
      "from sklearn.metrics import confusion_matrix, accuracy_score\n",
      "from sklearn.metrics import classification_report"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 3
    },
    {
     "cell_type": "heading",
     "level": 2,
     "metadata": {},
     "source": [
      "Getting all the functions I need to test out the code and getting verlander in right format"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def split_test_train(pitcher_df, date, date_col = 'date'):\n",
      "    '''Takes in a pandas df of pitcher data (one or more pitchers) and splits it into testing and training features and targets.\n",
      "    It also splits Categorical variables up and binarizes them as their own columns\n",
      "    Input Args:\n",
      "        pitcher_df: Pandas dataframe containing all pitch data for a single pitcher\n",
      "        date: string in the form yyyy-mm-dd, specifying the cutoff for splitting test/train\n",
      "    Output:\n",
      "        Dictionary containing:\n",
      "            train_data: Pandas feature DF for training data\n",
      "            train_targets: Pandas Series of training data targets (pitch_type)\n",
      "            test_data: Pandas feature DF for testing data\n",
      "            test_targets: Pandas Series of testing data targets (pitch_type)'''\n",
      "    \n",
      "    #Reshaping\n",
      "    from pandas.core.reshape import get_dummies #Note: requires Pandas 0.16 +\n",
      "    pitcher_subset = pitcher_df.drop('pitch_type', axis = 1)\n",
      "    pitcher_subset = get_dummies(pitcher_subset)\n",
      "    \n",
      "    #split the data and store it in a dictionary\n",
      "    pitcher_dict = {}\n",
      "    pitcher_dict['train_data'] = pitcher_subset[pitcher_subset[date_col] < date].drop(date_col, axis = 1)\n",
      "    pitcher_dict['train_targets'] = pitcher_df['pitch_type'][pitcher_df[date_col] < date].astype('category')\n",
      "    pitcher_dict['test_data'] = pitcher_subset[pitcher_subset[date_col] >= date].drop(date_col, axis = 1)\n",
      "    pitcher_dict['test_targets'] = pitcher_df['pitch_type'][pitcher_df[date_col] >= date].astype('category')\n",
      "    \n",
      "    return pitcher_dict\n",
      "\n",
      "def get_date_from_gameday_id(pitch_df):\n",
      "    '''Function to extract the pitch date from the \"gameday_link\" column of a pitch DF\n",
      "    Input:\n",
      "        pitch_df: Pandas DF containing the column \"gameday_link\"\n",
      "    Output:\n",
      "        Same Pandas dataframe as input except that it now contains a new Pandas datetime column in the format \"yyyy-mm-dd\"'''\n",
      "    \n",
      "    pitch_df['date'] = pitch_df['gameday_link'].str.slice(start = 4, stop = 14)\n",
      "    pitch_df['date'] = pitch_df['date'].str.replace(\"_\", \"-\")\n",
      "    pitch_df['date'] = pd.to_datetime(pitch_df['date'])\n",
      "    return pitch_df"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 4
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "verlander = pd.read_csv('../../data/input/sample data/verlander2.csv')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 5
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#get rid of missing pitch_type data\n",
      "verlander = verlander[verlander['pitch_type'].notnull()]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 6
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "verlander = get_date_from_gameday_id(verlander)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 7
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#pick columns that are relevant for prediction\n",
      "cols_of_interest = ['home_team_runs', 'away_team_runs', 'inning_side',\n",
      "                    'inning', 'stand', 'batter_name', 'balls', 'strikes', 'runners',\n",
      "                    'scorediff', 'season_pitch_count', 'times_faced', 'date', 'pitch_type']"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 8
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#Get rid of nulls\n",
      "verlander = verlander[verlander['home_team_runs'].notnull()]\n",
      "verlander = verlander[cols_of_interest]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 9
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "verlander.columns.to_series().groupby(verlander.dtypes).groups"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 10,
       "text": [
        "{dtype('<M8[ns]'): ['date'],\n",
        " dtype('int64'): ['inning',\n",
        "  'balls',\n",
        "  'strikes',\n",
        "  'scorediff',\n",
        "  'season_pitch_count',\n",
        "  'times_faced'],\n",
        " dtype('float64'): ['home_team_runs', 'away_team_runs'],\n",
        " dtype('O'): ['inning_side', 'stand', 'batter_name', 'runners', 'pitch_type']}"
       ]
      }
     ],
     "prompt_number": 10
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#Convert Categorical variables to dummies\n",
      "data_dict = split_test_train(verlander, '2013-01-01')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 11
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "data_dict['test_data'].head()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "html": [
        "<div style=\"max-width:1500px;overflow:auto;\">\n",
        "<table border=\"1\" class=\"dataframe\">\n",
        "  <thead>\n",
        "    <tr style=\"text-align: right;\">\n",
        "      <th></th>\n",
        "      <th>home_team_runs</th>\n",
        "      <th>away_team_runs</th>\n",
        "      <th>inning</th>\n",
        "      <th>balls</th>\n",
        "      <th>strikes</th>\n",
        "      <th>scorediff</th>\n",
        "      <th>season_pitch_count</th>\n",
        "      <th>times_faced</th>\n",
        "      <th>inning_side_bottom</th>\n",
        "      <th>inning_side_top</th>\n",
        "      <th>...</th>\n",
        "      <th>batter_name_Zachary Cozart</th>\n",
        "      <th>batter_name_Zachary Walters</th>\n",
        "      <th>runners_1b</th>\n",
        "      <th>runners_1b2b</th>\n",
        "      <th>runners_1b3b</th>\n",
        "      <th>runners_2b</th>\n",
        "      <th>runners_2b3b</th>\n",
        "      <th>runners_3b</th>\n",
        "      <th>runners_empty</th>\n",
        "      <th>runners_loaded</th>\n",
        "    </tr>\n",
        "  </thead>\n",
        "  <tbody>\n",
        "    <tr>\n",
        "      <th>20210</th>\n",
        "      <td>0</td>\n",
        "      <td>2</td>\n",
        "      <td>1</td>\n",
        "      <td>0</td>\n",
        "      <td>0</td>\n",
        "      <td>2</td>\n",
        "      <td>168</td>\n",
        "      <td>1</td>\n",
        "      <td>1</td>\n",
        "      <td>0</td>\n",
        "      <td>...</td>\n",
        "      <td>0</td>\n",
        "      <td>0</td>\n",
        "      <td>0</td>\n",
        "      <td>0</td>\n",
        "      <td>0</td>\n",
        "      <td>0</td>\n",
        "      <td>0</td>\n",
        "      <td>0</td>\n",
        "      <td>1</td>\n",
        "      <td>0</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>20211</th>\n",
        "      <td>0</td>\n",
        "      <td>2</td>\n",
        "      <td>1</td>\n",
        "      <td>0</td>\n",
        "      <td>1</td>\n",
        "      <td>2</td>\n",
        "      <td>169</td>\n",
        "      <td>1</td>\n",
        "      <td>1</td>\n",
        "      <td>0</td>\n",
        "      <td>...</td>\n",
        "      <td>0</td>\n",
        "      <td>0</td>\n",
        "      <td>0</td>\n",
        "      <td>0</td>\n",
        "      <td>0</td>\n",
        "      <td>0</td>\n",
        "      <td>0</td>\n",
        "      <td>0</td>\n",
        "      <td>1</td>\n",
        "      <td>0</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>20212</th>\n",
        "      <td>0</td>\n",
        "      <td>2</td>\n",
        "      <td>1</td>\n",
        "      <td>0</td>\n",
        "      <td>2</td>\n",
        "      <td>2</td>\n",
        "      <td>170</td>\n",
        "      <td>1</td>\n",
        "      <td>1</td>\n",
        "      <td>0</td>\n",
        "      <td>...</td>\n",
        "      <td>0</td>\n",
        "      <td>0</td>\n",
        "      <td>0</td>\n",
        "      <td>0</td>\n",
        "      <td>0</td>\n",
        "      <td>0</td>\n",
        "      <td>0</td>\n",
        "      <td>0</td>\n",
        "      <td>1</td>\n",
        "      <td>0</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>20213</th>\n",
        "      <td>0</td>\n",
        "      <td>2</td>\n",
        "      <td>1</td>\n",
        "      <td>1</td>\n",
        "      <td>2</td>\n",
        "      <td>2</td>\n",
        "      <td>171</td>\n",
        "      <td>1</td>\n",
        "      <td>1</td>\n",
        "      <td>0</td>\n",
        "      <td>...</td>\n",
        "      <td>0</td>\n",
        "      <td>0</td>\n",
        "      <td>0</td>\n",
        "      <td>0</td>\n",
        "      <td>0</td>\n",
        "      <td>0</td>\n",
        "      <td>0</td>\n",
        "      <td>0</td>\n",
        "      <td>1</td>\n",
        "      <td>0</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>20214</th>\n",
        "      <td>0</td>\n",
        "      <td>2</td>\n",
        "      <td>1</td>\n",
        "      <td>0</td>\n",
        "      <td>0</td>\n",
        "      <td>2</td>\n",
        "      <td>172</td>\n",
        "      <td>1</td>\n",
        "      <td>1</td>\n",
        "      <td>0</td>\n",
        "      <td>...</td>\n",
        "      <td>0</td>\n",
        "      <td>0</td>\n",
        "      <td>0</td>\n",
        "      <td>0</td>\n",
        "      <td>0</td>\n",
        "      <td>0</td>\n",
        "      <td>0</td>\n",
        "      <td>0</td>\n",
        "      <td>1</td>\n",
        "      <td>0</td>\n",
        "    </tr>\n",
        "  </tbody>\n",
        "</table>\n",
        "<p>5 rows \u00d7 612 columns</p>\n",
        "</div>"
       ],
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 12,
       "text": [
        "       home_team_runs  away_team_runs  inning  balls  strikes  scorediff  \\\n",
        "20210               0               2       1      0        0          2   \n",
        "20211               0               2       1      0        1          2   \n",
        "20212               0               2       1      0        2          2   \n",
        "20213               0               2       1      1        2          2   \n",
        "20214               0               2       1      0        0          2   \n",
        "\n",
        "       season_pitch_count  times_faced  inning_side_bottom  inning_side_top  \\\n",
        "20210                 168            1                   1                0   \n",
        "20211                 169            1                   1                0   \n",
        "20212                 170            1                   1                0   \n",
        "20213                 171            1                   1                0   \n",
        "20214                 172            1                   1                0   \n",
        "\n",
        "            ...        batter_name_Zachary Cozart  \\\n",
        "20210       ...                                 0   \n",
        "20211       ...                                 0   \n",
        "20212       ...                                 0   \n",
        "20213       ...                                 0   \n",
        "20214       ...                                 0   \n",
        "\n",
        "       batter_name_Zachary Walters  runners_1b  runners_1b2b  runners_1b3b  \\\n",
        "20210                            0           0             0             0   \n",
        "20211                            0           0             0             0   \n",
        "20212                            0           0             0             0   \n",
        "20213                            0           0             0             0   \n",
        "20214                            0           0             0             0   \n",
        "\n",
        "       runners_2b  runners_2b3b  runners_3b  runners_empty  runners_loaded  \n",
        "20210           0             0           0              1               0  \n",
        "20211           0             0           0              1               0  \n",
        "20212           0             0           0              1               0  \n",
        "20213           0             0           0              1               0  \n",
        "20214           0             0           0              1               0  \n",
        "\n",
        "[5 rows x 612 columns]"
       ]
      }
     ],
     "prompt_number": 12
    },
    {
     "cell_type": "heading",
     "level": 2,
     "metadata": {},
     "source": [
      "Write functions to collect predictions from multiple classifiers and vote on most commonly occurring prediction"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Create Generic Function to run a classifier\n",
      "def collect_classifier_predictions(data_dict, **kwargs):\n",
      "    \"\"\"Given a data dictionary  containing 'train_data' and 'test_data' (as pandas DFs) and classifiers (kwargs),\n",
      "    This runs the classifier and outputs the predictions of each classifier as a dictionary.\n",
      "    Input:\n",
      "        data_dict: the data dictionary containing all the train/test data/targets\n",
      "        kwargs: sequence of classifiers (e.g. RF = RandomForest(), lin_svc = LinearSVC()...\n",
      "    Output:\n",
      "        dictionary of predictions where the key is the classifier label given in kwargs and the value is a list of predictions\"\"\"\n",
      "    \n",
      "    pred_dict = {}\n",
      "    for classifier in kwargs.keys():\n",
      "        \n",
      "        # Fit a model on all the data and features\n",
      "        kwargs[classifier].fit(data_dict['train_data'], data_dict['train_targets'])\n",
      "\n",
      "        # Make predictions on dev data\n",
      "        pred_dict[classifier] = kwargs[classifier].predict(data_dict['test_data'])\n",
      "    \n",
      "    # Return the dev performance score.\n",
      "    return pred_dict"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 13
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "pred_dict = collect_classifier_predictions(data_dict,\n",
      "                                           RF = RandomForestClassifier(), \n",
      "                                           log_reg = LogisticRegression(), \n",
      "                                           gaussian_nb = GaussianNB(),\n",
      "                                           linear_svc = LinearSVC())"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n"
       ]
      }
     ],
     "prompt_number": 15
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def ensemble_voting(predictions_dict):\n",
      "    '''Takes in the predictions dictionary output from collect_classifier_predictions and returns pred with most votes'''\n",
      "    \n",
      "    from collections import defaultdict, Counter\n",
      "    \n",
      "    #Instantiate an object to hold the combined scores from each classifier\n",
      "    scores = defaultdict(list)\n",
      "    \n",
      "    #Run through each classifier and get voting predictions\n",
      "    for classifier in predictions_dict.keys():\n",
      "        \n",
      "        for i, prediction in enumerate(predictions_dict[classifier]):\n",
      "            scores[i].append(prediction)\n",
      "    \n",
      "    final_preds = []\n",
      "    for i in sorted(scores):\n",
      "        final_preds.append(Counter(scores[i]).most_common(1)[0][0])\n",
      "    \n",
      "    return pd.Series(final_preds, dtype = 'object')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 16
    },
    {
     "cell_type": "heading",
     "level": 3,
     "metadata": {},
     "source": [
      "Checking some results"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "pred_dict"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 17,
       "text": [
        "{'RF': array(['FF', 'FF', 'FF', ..., 'FF', 'FF', 'FF'], dtype=object),\n",
        " 'gaussian_nb': array(['FT', 'FT', 'FT', ..., 'FT', 'FT', 'FT'], dtype=object),\n",
        " 'linear_svc': array(['FF', 'FF', 'CU', ..., 'CH', 'CH', 'CH'], dtype=object),\n",
        " 'log_reg': array(['FF', 'FF', 'CU', ..., 'FF', 'FF', 'FF'], dtype=object)}"
       ]
      }
     ],
     "prompt_number": 17
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "ensemble_voting(pred_dict)[len(pred_dict['RF']) - 3:]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 18,
       "text": [
        "7204    FF\n",
        "7205    FF\n",
        "7206    FF\n",
        "dtype: object"
       ]
      }
     ],
     "prompt_number": 18
    },
    {
     "cell_type": "heading",
     "level": 2,
     "metadata": {},
     "source": [
      "Function to pickle/serialize a model"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def run_classifier(classifier, data_dict):\n",
      "    \"\"\"Given a classifier and a data dictionary containing 'train_data' and 'test_data' (as pandas DFs),\n",
      "    This runs the classifier and outputs the accuracy of the classifier on the test data.\"\"\"\n",
      "    \n",
      "    # Fit a model on all the data and features\n",
      "    classifier.fit(data_dict['train_data'], data_dict['train_targets'])\n",
      "\n",
      "    # Make predictions on dev data\n",
      "    dev_predictions = classifier.predict(data_dict['test_data'])\n",
      "    \n",
      "    # Return the dev performance score.\n",
      "    return accuracy_score(data_dict['test_targets'], dev_predictions)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 20
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "run_classifier(RandomForestClassifier(), data_dict)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 21,
       "text": [
        "0.443041487442764"
       ]
      }
     ],
     "prompt_number": 21
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "test_classifier = RandomForestClassifier().fit(data_dict['train_data'], data_dict['train_targets'])"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 22
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def save_model(model, model_name, save_dir = '../models/', record_keeping_file = '../models/record_keeping.csv'):\n",
      "    '''In order to manage our models, we need to keep track of where and when they came from. Each time\n",
      "    this function is called, it serializes 'model' to a file called 'model_name'.pickle in a newly created folder located\n",
      "    in 'save_dir' and writes a log of the event as a new line in 'record_keeping_file'\n",
      "    '''\n",
      "    \n",
      "    #Import the serializer and csv writer\n",
      "    import pickle\n",
      "    from datetime import datetime\n",
      "    import os\n",
      "    \n",
      "    #Create the new folder to house the model\n",
      "    new_folder = save_dir + model_name\n",
      "    if not os.path.exists(new_folder):\n",
      "        os.makedirs(new_folder)\n",
      "    \n",
      "    #Serialize the model\n",
      "    complete_fp = new_folder + '/' + model_name + '.pickle'\n",
      "    with open(complete_fp, 'wb') as f:\n",
      "        joblib.dump(model, complete_fp)\n",
      "    \n",
      "    #Write the event to the record-keeping file (format = model_name, serialized_filepath, current_time)\n",
      "    with open(record_keeping_file, 'a') as f:\n",
      "        f.write(model_name + ',' + complete_fp + ',' + str(datetime.now()) + '\\n')\n",
      "    \n",
      "    return"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 53
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#Write the initial record-keeping file\n",
      "record_keeper_file = '../../models/record_keeping.csv'\n",
      "with open(record_keeper_file, 'w') as f:\n",
      "    f.write('model_name,serialized_filepath,creation_date\\n')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 58
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#Testing out a model\n",
      "save_model(test_classifier, 'verlander_rf_testing_function_zb', save_dir = '../../models/', record_keeping_file=record_keeper_file)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 59
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#read it back in and make some predictions\n",
      "from sklearn.externals import joblib\n",
      "clf = joblib.load('../../models/' + 'rf_testing_function_zb.pickle')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 44
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "clf.predict(data_dict['test_data'])"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 46,
       "text": [
        "array(['FF', 'CH', 'CH', ..., 'FF', 'FF', 'FF'], dtype=object)"
       ]
      }
     ],
     "prompt_number": 46
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    }
   ],
   "metadata": {}
  }
 ]
}